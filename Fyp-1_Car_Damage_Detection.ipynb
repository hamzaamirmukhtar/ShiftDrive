{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Damage Detection Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport os\nfrom matplotlib import pyplot as plt\nimport cv2\nimport random\nimport pickle\nimport tensorflow as tf \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nimport pickle\nfrom keras.models import model_from_json\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\n\ndef Load_Data(TRAIN_DIR,TEST_DIR,CATEGORIES):\n\n    file_list = []\n    class_list = []\n\n    \n    # The size of the images that your neural network will use\n    IMG_SIZE = 200\n\n    # Checking or all images in the data folder\n    for category in CATEGORIES :\n        path = os.path.join(TRAIN_DIR, category)\n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n\n    training_data = []\n\n    def create_training_data():\n        for category in CATEGORIES :\n            path = os.path.join(TRAIN_DIR, category)\n            class_num = CATEGORIES.index(category)\n            for img in os.listdir(path):\n                try :\n                    img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                    training_data.append([new_array, class_num])\n                except Exception as e:\n                    pass\n\n    create_training_data()\n\n    random.shuffle(training_data)\n\n    X = [] #features\n    y = [] #labels\n\n    for features, label in training_data:\n        X.append(features)\n        y.append(label)\n\n    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\n    # Creating the files containing all the information about your model\n    pickle_out = open(\"X.pickle\", \"wb\")\n    pickle.dump(X, pickle_out)\n    pickle_out.close()\n\n    pickle_out = open(\"y.pickle\", \"wb\")\n    pickle.dump(y, pickle_out)\n    pickle_out.close()\n\n    pickle_in = open(\"X.pickle\", \"rb\")\n    X = pickle.load(pickle_in)\n    return TRAIN_DIR,TEST_DIR,CATEGORIES\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\n\ndef Transfer_learning(CLASSES): \n\n    #CLASSES = 3\n\n    # setup model\n    base_model = InceptionV3(weights='imagenet', include_top=False)\n\n    x = base_model.output\n    x = GlobalAveragePooling2D(name='avg_pool')(x)\n    x = Dropout(0.4)(x)\n    predictions = Dense(CLASSES, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    # transfer learning\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer='Adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nWIDTH = 200\nHEIGHT = 200\nBATCH_SIZE = 12\n\ndef Data_Augmenter():\n# data prep\n    train_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\n    validation_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\n    train_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    target_size=(HEIGHT, WIDTH),\n\t\tbatch_size=BATCH_SIZE,\n\t\tclass_mode='categorical')\n    \n    validation_generator = validation_datagen.flow_from_directory(\n    TEST_DIR,\n    target_size=(HEIGHT, WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical')\n    return train_generator,validation_generator\n\n\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Display_Augmented_Data():\n    x_batch, y_batch = next(train_generator)\n\n    plt.figure(figsize=(12, 9))\n    for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n        plt.subplot(4, 8, k+1)\n        plt.imshow((img + 1) / 2)\n        plt.axis('off')\n\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR,TEST_DIR,CATEGORIES=Load_Data(\"../input/damaged-cars-data/train\",\"../input/damaged-cars-data/test\",[\"bumper\",\"head light\",\"window\"])\nmodel=Transfer_learning(3)\n","execution_count":5,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87916544/87910968 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,validation_generator=Data_Augmenter()\nDisplay_Augmented_Data()","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 640 images belonging to 3 classes.\nFound 181 images belonging to 3 classes.\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'train_generator' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-8fb4023923eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mData_Augmenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDisplay_Augmented_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-e76b50b21071>\u001b[0m in \u001b[0;36mDisplay_Augmented_Data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDisplay_Augmented_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 20\nBATCH_SIZE = 12\nSTEPS_PER_EPOCH = 10\nVALIDATION_STEPS = 10\n\nMODEL_FILE = 'filename.model'\n\nhistory = model.fit_generator(\n    train_generator,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=validation_generator,\n    validation_steps=VALIDATION_STEPS)\n  \nmodel.save(MODEL_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training(history):\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n  epochs = range(len(acc))\n  \n  plt.plot(epochs, acc, 'r.')\n  plt.plot(epochs, val_acc, 'r')\n  plt.title('Training and validation accuracy')\n  \n  plt.figure()\n  plt.plot(epochs, loss, 'r.')\n  plt.plot(epochs, val_loss, 'r-')\n  plt.title('Training and validation loss')\n  plt.show()\n  \nplot_training(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfrom keras.preprocessing import image\nfrom keras.models import load_model\n\n\ndef predict(model, img):\n    \"\"\"Run model prediction on image\n    Args:\n        model: keras model\n        img: PIL format image\n    Returns:\n        list of predicted labels and their probabilities \n    \"\"\"\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    preds = model.predict(x)\n    return preds[0]\n\n\ndef plot_preds(img, preds):\n    \"\"\"Displays image and the top-n predicted probabilities in a bar graph\n    Args:\n        preds: list of predicted labels and their probabilities\n    \"\"\"\n    labels = (\"bumper\",\"head lamp\",\"window\")\n    gs = gridspec.GridSpec(2, 1, height_ratios=[4, 1])\n    plt.figure(figsize=(8,8))\n    plt.subplot(gs[0])\n    plt.imshow(np.asarray(img))\n    plt.subplot(gs[1])\n    plt.barh([0, 1], preds, alpha=0.5)\n    plt.yticks([0, 1], labels)\n    plt.xlabel('Probability')\n    plt.xlim(0, 1)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model(MODEL_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL.Image as Image\nfrom IPython.display import display\nimg = image.load_img('../input/damaged-cars-data/test/head light/1022.jpeg', target_size=(HEIGHT, WIDTH))\npreds = predict(model, img)\n\nif (max(preds)==preds[0]):\n    part=\"Bumper\"\nelif(max(preds)==preds[1]):\n    part=\"Head Lamp\"\nelse:\n    part=\"Windscreen\"\nprint (\"Damaged Part of your car is : \"+ part)\ndisplay(Image.open(\"../input/damaged-cars-data/test/head light/1022.jpeg\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}